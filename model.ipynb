{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "847be261-b3d8-41ce-aacd-4c91d139f4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 19:54:42.269619: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import collections\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_fscore_support, average_precision_score\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import precision_recall_curve, auc, confusion_matrix, accuracy_score, plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, LeakyReLU, Dense, Reshape, Flatten, Activation\n",
    "from tensorflow.keras.layers import Dropout, multiply, GaussianNoise, MaxPooling2D, concatenate\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a87275e8-4902-4429-a040-2fd8b66679a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b591b28e-a2e8-4042-ba2a-2906db2406f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.python.platform.build_info as build\n",
    "print(build.build_info['cuda_version'])\n",
    "print(build.build_info['cudnn_version'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "653c2ebc-c49c-4e57-94bf-6360e1face6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bd7587f-2a6a-4b62-b1d5-7f65ea037ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_frag = pd.concat(map(pd.read_csv, glob.glob('data/csv_fragmentedV3/*.csv')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5918151-34b0-4aab-860b-b860f93a86d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('data/test/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0096dd1b-0de7-4f06-a8ea-28b9484d67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat(map(pd.read_csv, glob.glob('data/test/*.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1256750a-4143-4c17-be0f-e856829dcae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pascal/anaconda3/envs/master/lib/python3.9/site-packages/sklearn/base.py:288: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.0.1 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "filename = 'data/preprocessed_data.pickle'\n",
    "\n",
    "input_file = open(filename, 'rb')\n",
    "preprocessed_data = pickle.load(input_file)\n",
    "input_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33efc897-ca02-4e36-bf6a-454bc457ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessed_data['le']\n",
    "x_train = preprocessed_data['x_train']\n",
    "y_train = preprocessed_data['y_train']\n",
    "x_test = preprocessed_data['x_test']\n",
    "y_test = preprocessed_data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76334c01-0405-4d68-bc00-5dc8f663f8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Type\n",
       "0  Benign\n",
       "1     Bot"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(le.classes_, columns=['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d73365c5-6294-45ac-a3b1-59dfa8e80276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1065425, 78)\n",
      "(1065425,)\n",
      "(188017, 78)\n",
      "(188017,)\n"
     ]
    }
   ],
   "source": [
    "assert x_train.shape[0] == y_train.shape[0]\n",
    "assert x_test.shape[0] == y_test.shape[0]\n",
    "assert x_train.shape[1] == x_test.shape[1]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44f20ec5-564d-460d-bdca-df741b0caa2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c861f76-50ed-4e91-8bcd-c704f0b18cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels normal data as 0, anomalies as 1\n",
    "\n",
    "def make_labels_binary(label_encoder, labels):\n",
    "    normal_data_index = np.where(label_encoder.classes_ == 'Benign')[0][0]\n",
    "    new_labels = labels.copy()\n",
    "    new_labels[labels != normal_data_index] = 1\n",
    "    new_labels[labels == normal_data_index] = 0\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eb5a43a-1985-468f-b61c-fd75efe70b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = make_labels_binary(le, y_train)\n",
    "y_test = make_labels_binary(le, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d7ad8e6-02dc-4e2b-bcc9-be3a0256dd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of anomalies in y_train: 421,003\n",
      "Number of anomalies in y_test: 74,105\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of anomalies in y_train: {y_train.sum():,}')\n",
    "print(f'Number of anomalies in y_test: {y_test.sum():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dceb226-42ee-4222-9106-cbb497ed7aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_len = len(x_train)\n",
    "temp_df = x_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a59e28b3-a8bf-431f-bab5-f5d59a434ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting only Normal Network packets in training set (excluding anomalies)\n",
    "temp_df['label'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65651f06-098f-48e1-8e90-2adad9a715a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has now the size of 0.6 of the original dataset\n"
     ]
    }
   ],
   "source": [
    "temp_df = temp_df.loc[temp_df['label'] == 0]\n",
    "temp_df = temp_df.drop('label', axis=1)\n",
    "x_train = temp_df.copy()\n",
    "\n",
    "print(\n",
    "    f'Dataset has now the size of {(len(x_train)/prev_len):.2} of the original dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f47a9c01-8cd7-4e80-bf8e-4436ee58d34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b176f014-fd21-41ca-9229-9a3b271802b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "dataset['x_train'] = x_train.astype(np.float32)\n",
    "dataset['y_train'] = y_train.astype(np.float32)\n",
    "dataset['x_test'] = x_test.astype(np.float32)\n",
    "dataset['y_test'] = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f0262a9-c3e2-4a5a-92fe-cc56ad1355f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Normal Network packets in the test set: 113912\n",
      "Number of Anomalous Network packets in the test set: 74105\n",
      "Ratio of anomalous to normal network packets:  0.3941398916055463\n"
     ]
    }
   ],
   "source": [
    "normals = collections.Counter(y_test)[0]\n",
    "anomalies = collections.Counter(y_test)[1]\n",
    "anomalies_percentage = anomalies / (normals + anomalies)\n",
    "print('Number of Normal Network packets in the test set:', normals)\n",
    "print('Number of Anomalous Network packets in the test set:', anomalies)\n",
    "print('Ratio of anomalous to normal network packets: ', anomalies_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53e75030-80cd-4247-b911-2172608e7a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(optim):\n",
    "    generator = Sequential()\n",
    "    generator.add(Dense(64, input_dim=78,\n",
    "                  kernel_initializer=initializers.glorot_normal(seed=42)))\n",
    "    generator.add(Activation('tanh'))\n",
    "\n",
    "    generator.add(Dense(128))\n",
    "    generator.add(Activation('tanh'))\n",
    "\n",
    "    generator.add(Dense(78, activation='tanh'))\n",
    "\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=optim)\n",
    "\n",
    "    return generator\n",
    "\n",
    "\n",
    "def get_discriminator(optim):\n",
    "\n",
    "    discriminator = Sequential()\n",
    "\n",
    "    discriminator.add(Dense(256, input_dim=78,\n",
    "                      kernel_initializer=initializers.glorot_normal(seed=42)))\n",
    "    discriminator.add(Activation(tf.nn.leaky_relu))\n",
    "    discriminator.add(Dropout(0.2))\n",
    "\n",
    "    discriminator.add(Dense(1))\n",
    "    discriminator.add(Activation('sigmoid'))\n",
    "\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=optim)\n",
    "\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17baad3d-1fb4-4f4c-bba6-446a934cd7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gan_network(discriminator, generator, optim, input_dim=78):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input(shape=(input_dim,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "\n",
    "    gan = Model(inputs=gan_input, outputs=gan_output)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=optim)\n",
    "\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "334d789f-0983-4e45-813d-8b77a5b1614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "momentum = 0.3\n",
    "batch_size = 512\n",
    "epochs = 100\n",
    "adam = Adam(lr=learning_rate, beta_1=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ff78f5b-eace-4eb5-b6a3-29ffddbcf833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the GAN\n",
    "x_train, y_train, x_test, y_test = dataset['x_train'], dataset['y_train'], dataset['x_test'], dataset['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edaa7800-b777-4963-ad4f-9b94198ecb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                  | 0/125800 [00:00<?, ?it/s]2023-02-18 19:54:53.539449: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-02-18 19:54:53.540131: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-02-18 19:54:53.570886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 19:54:53.571088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:25:00.0 name: NVIDIA GeForce RTX 3070 computeCapability: 8.6\n",
      "coreClock: 1.725GHz coreCount: 46 deviceMemorySize: 7.78GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2023-02-18 19:54:53.571110: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-02-18 19:54:53.587443: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-02-18 19:54:53.587488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-02-18 19:54:53.597130: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-02-18 19:54:53.597378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-02-18 19:54:53.614071: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-02-18 19:54:53.616850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-02-18 19:54:53.645812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-02-18 19:54:53.646033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 19:54:53.646213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 19:54:53.646300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-02-18 19:54:53.646675: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-18 19:54:53.647272: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-02-18 19:54:53.647339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 19:54:53.647439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:25:00.0 name: NVIDIA GeForce RTX 3070 computeCapability: 8.6\n",
      "coreClock: 1.725GHz coreCount: 46 deviceMemorySize: 7.78GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2023-02-18 19:54:53.647474: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-02-18 19:54:53.647489: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-02-18 19:54:53.647498: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-02-18 19:54:53.647507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-02-18 19:54:53.647516: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-02-18 19:54:53.647525: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-02-18 19:54:53.647534: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-02-18 19:54:53.647543: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-02-18 19:54:53.647584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 19:54:53.647705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 19:54:53.647788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-02-18 19:54:53.647997: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-02-18 19:54:55.267850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-02-18 19:54:55.267870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-02-18 19:54:55.267875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-02-18 19:54:55.268313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 19:54:55.268465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 19:54:55.268588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 19:54:55.268690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5913 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:25:00.0, compute capability: 8.6)\n",
      "  0%|                                                                                                                                       | 1/125800 [00:01<64:25:18,  1.84s/it]2023-02-18 19:54:55.420762: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-02-18 19:54:55.436658: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3601660000 Hz\n",
      "2023-02-18 19:54:55.449567: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number params:  43919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 19:54:55.858045: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cwise_op_gpu_base.cc:89 : Internal: Failed to load in-memory CUBIN: CUDA_ERROR_NO_BINARY_FOR_GPU: no kernel image is available for execution on the device\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " Failed to load in-memory CUBIN: CUDA_ERROR_NO_BINARY_FOR_GPU: no kernel image is available for execution on the device\n\t [[node sequential/activation/Tanh (defined at tmp/ipykernel_11050/4044302038.py:21) ]] [Op:__inference_predict_function_274]\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m noise \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m[batch_size, \u001b[38;5;241m78\u001b[39m])\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Generate fake samples\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m generated_images \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Obtain a batch of normal network packets\u001b[39;00m\n\u001b[1;32m     24\u001b[0m image_batch \u001b[38;5;241m=\u001b[39m x_train[index \u001b[38;5;241m*\u001b[39m batch_size: (index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size]\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1820\u001b[0m, in \u001b[0;36mModel.predict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1818\u001b[0m   iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x)\n\u001b[1;32m   1819\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_predict_function()\n\u001b[0;32m-> 1820\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf_utils\u001b[38;5;241m.\u001b[39mto_numpy_or_python_type(outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:894\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    890\u001b[0m   _, _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    891\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    892\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    893\u001b[0m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[0;32m--> 894\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_with_cond\u001b[39m(inner_args, inner_kwds, inner_filtered_flat_args):\n\u001b[1;32m    898\u001b[0m   \u001b[38;5;124;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1914\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1917\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1920\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m     args,\n\u001b[1;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1923\u001b[0m     executing_eagerly)\n\u001b[1;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.9/site-packages/tensorflow/python/eager/function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    554\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    564\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    568\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/master/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m:  Failed to load in-memory CUBIN: CUDA_ERROR_NO_BINARY_FOR_GPU: no kernel image is available for execution on the device\n\t [[node sequential/activation/Tanh (defined at tmp/ipykernel_11050/4044302038.py:21) ]] [Op:__inference_predict_function_274]\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "# Calculating the number of batches based on the batch size\n",
    "batch_count = x_train.shape[0] // batch_size\n",
    "pbar = tqdm(total=epochs * batch_count, position=0, leave=True)\n",
    "gan_loss = []\n",
    "discriminator_loss = []\n",
    "\n",
    "# Inititalizing the network\n",
    "generator = get_generator(adam)\n",
    "discriminator = get_discriminator(adam)\n",
    "gan = make_gan_network(discriminator, generator, adam, input_dim=78)\n",
    "\n",
    "print(\"Number params: \", gan.count_params())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for index in range(batch_count):\n",
    "        pbar.update(1)\n",
    "        # Creating a random set of input noise and images\n",
    "        noise = np.random.normal(0, 1, size=[batch_size, 78])\n",
    "\n",
    "        # Generate fake samples\n",
    "        generated_images = generator.predict_on_batch(noise)\n",
    "\n",
    "        # Obtain a batch of normal network packets\n",
    "        image_batch = x_train[index * batch_size: (index + 1) * batch_size]\n",
    "\n",
    "        X = np.vstack((generated_images, image_batch))\n",
    "        y_dis = np.ones(2*batch_size)\n",
    "        y_dis[:batch_size] = 0\n",
    "\n",
    "        # Train discriminator\n",
    "        discriminator.trainable = True\n",
    "        d_loss = discriminator.train_on_batch(X, y_dis)\n",
    "\n",
    "        # Train generator\n",
    "        noise = np.random.uniform(0, 1, size=[batch_size, 78])\n",
    "        y_gen = np.ones(batch_size)\n",
    "        discriminator.trainable = False\n",
    "        g_loss = gan.train_on_batch(noise, y_gen)\n",
    "\n",
    "        # Record the losses\n",
    "        discriminator_loss.append(d_loss)\n",
    "        gan_loss.append(g_loss)\n",
    "\n",
    "    print(\"Epoch %d Batch %d/%d [D loss: %f] [G loss:%f]\" %\n",
    "          (epoch, index, batch_count, d_loss, g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a0cff-000b-41a1-b518-51f6513e90dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(discriminator_loss, label='Discriminator')\n",
    "plt.plot(gan_loss, label='Generator')\n",
    "plt.title(\"Training Loss GAN\")\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(figure_path + 'loss_gan.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c14407f-44d4-444d-94a7-0d0f2b60db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:20,.7f}'.format\n",
    "results_df = pd.concat([pd.DataFrame(results), pd.DataFrame(y_test)], axis=1)\n",
    "results_df.columns = ['results', 'y_test']\n",
    "print('Mean score for normal packets :',\n",
    "      results_df.loc[results_df['y_test'] == 0, 'results'].mean())\n",
    "print('Mean score for anomalous packets :',\n",
    "      results_df.loc[results_df['y_test'] == 1, 'results'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccae3f5-fa59-4f85-99f2-e122e0dce204",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00983f28-7313-4fb6-95ce-27646b0602f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, savefile, name, cmap=plt.cm.Greens):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title('Confusion matrix ' + name)\n",
    "    plt.colorbar()\n",
    "    plt.xticks(np.arange(2), ['Normal','Anomaly'], rotation=45)\n",
    "    plt.yticks(np.arange(2), ['Normal','Anomaly'])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    width, height = cm.shape\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            plt.annotate(str(cm[x][y]), xy=(y, x), \n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(savefile)\n",
    "\n",
    "def plot_accuracy(history, savefile, name):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.legend(['accuracy', 'val_accuracy'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy in percent')\n",
    "    plt.title(name)\n",
    "    plt.savefig(savefile)\n",
    "    \n",
    "def plot_loss(history, savefile, name):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.legend(['loss', 'val_loss'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(name)\n",
    "    plt.savefig(savefile)\n",
    "    \n",
    "def plot_roc(tpr, fpr, roc_auc, savefile, name):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(fpr, tpr, lw=1, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='lime', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC ' + name)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(savefile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc85111-50ae-441e-b7da-c8ad9b8ef4d9",
   "metadata": {},
   "source": [
    "## Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3873abc-4e65-4ded-838d-6bc4a0baaeba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtaining the lowest \"anomalies_percentage\" score\n",
    "per = np.percentile(results, anomalies_percentage*100)\n",
    "y_pred = results.copy()\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294689a6-4e38-4595-9548-a47649d8902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding based on the score\n",
    "inds = (y_pred > per)\n",
    "inds_comp = (y_pred <= per)\n",
    "y_pred[inds] = 0\n",
    "y_pred[inds_comp] = 1\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    y_test, y_pred, average='binary')\n",
    "print('Accuracy Score :', accuracy_score(y_test, y_pred))\n",
    "print('Precision :', precision)\n",
    "print('Recall :', recall)\n",
    "print('F1 :', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a0379f-cffd-4ed4-aadc-f416146c9acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "auc_curve = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d11e3-9df8-44f5-b1e3-554baa1fb90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(tpr, fpr, auc_curve, figure_path + 'confusion_gan.png', 'GAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a51574-4dbe-46d8-bda3-d1cfaaa6fb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba80d3-e9c8-4061-abac-52b95ba7e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, figure_path + 'confusion_gan.png', 'GAN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
